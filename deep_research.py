import json
from langchain_ollama import ChatOllama
from langchain_core.prompts import PromptTemplate
from langchain_community.tools import DuckDuckGoSearchResults
from langchain.agents import Tool, create_react_agent, AgentExecutor
from langchain_core.output_parsers import StrOutputParser
import re
from glob import glob
import os

# 1. LLM ë° ê²€ìƒ‰ ë„êµ¬ ì„¤ì •
llm = ChatOllama(
    model="qwen3:32b",
    base_url="http://192.168.120.102:11434",
    temperature=0
)

search = DuckDuckGoSearchResults()
tools = [
    Tool(
        name="web_search",
        func=search.run,
        description="A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query. Output is a JSON string of a list of dictionaries with 'title', 'snippet', and 'link' keys.",
    )
]

# 2. Deep Researchë¥¼ ìœ„í•œ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ ì •ì˜
# ReAct ì—ì´ì „íŠ¸ì˜ í‘œì¤€ í”„ë¡¬í”„íŠ¸ í˜•ì‹ì— ë§ì¶° ìˆ˜ì •
prompt_template = """
You are an expert business analyst and researcher. Your mission is to perform 'Deep Research' on the initial SWOT analysis provided. You must use web searches to verify and deepen the insights for each category.

**Workflow:**
1.  **Formulate a Research Plan:** First, review the entire SWOT analysis. Then, formulate a concise research plan with 2-4 high-impact search queries to verify the most critical claims. **To avoid being rate-limited, be efficient: combine related topics into a single query where possible.**
2.  **Execute & Synthesize:** Use the 'web_search' tool to execute your planned queries. The tool will return a list of search results with titles, snippets, and links. Extract the most relevant information and the corresponding link to use as a source.
3.  **Write Final Report:** Once your research is complete, write a comprehensive report in the 'Final Answer'. Your report must be analytical. For each point you make, you must cite the specific data or finding from your research and include the source URL. For example: "The initial analysis noted a market growth opportunity. This is supported by a report from [Source Name], which states the market will grow by 15% annually (Source: [link from search result])."

**Available Tools:**
{tools}

**Begin Analysis!**

**Initial SWOT Analysis:**
{input}

{agent_scratchpad}

---
**CRITICAL: You must strictly follow the response format below. Do not add any other text outside this format.**

Thought: I need to analyze the current situation and decide what to do next, concisely.
Action: The tool to use, which must be one of [{tool_names}].
Action Input: The input query for the tool.
Observation: The result of the tool.
... (this Thought/Action/Action Input/Observation cycle can repeat N times)
Thought: I have now gathered enough information and can formulate the final answer.
Final Answer: [The final, comprehensive deep research report. **For each point, you must cite specific data and the source URL from your web search.**]
"""

prompt = PromptTemplate.from_template(prompt_template)


# 3. ì—ì´ì „íŠ¸ ë° ì‹¤í–‰ê¸° ìƒì„±
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,  # ì—ì´ì „íŠ¸ì˜ ìƒê° ê³¼ì •ì„ ë³¼ ìˆ˜ ìˆë„ë¡ ì„¤ì •
    handle_parsing_errors=True
)

# 4. ë©”ì¸ ì‹¤í–‰ ë¡œì§
if __name__ == "__main__":
    swot_files = glob('./result/swot_analysis_*.json')
    
    for output in swot_files:
        try:
            with open(output, 'r', encoding='utf-8') as f:
                swot_data = json.load(f)
        except FileNotFoundError:
            print("ì˜¤ë¥˜: 'result/swot_analysis.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë¨¼ì € 'python SWOT.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ë¶„ì„ íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
            exit()

        swot_input_string = json.dumps(swot_data, ensure_ascii=False, indent=2)

        print("=" * 30)
        print("ğŸ¤– Deep Research ì—ì´ì „íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("=" * 30)
        
        result = agent_executor.invoke({
            "input": swot_input_string,
        })

        print("\n" + "=" * 30)
        print("âœ… Deep Research ìµœì¢… ë³´ê³ ì„œ (ì˜ë¬¸)")
        print("=" * 30)
        print(result['output']) 

        korean_report = "" # ë²ˆì—­ë³¸ì„ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”
        # 5. ìµœì¢… ë³´ê³ ì„œë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­
        if result['output']:
            print("\n" + "=" * 30)
            print("ğŸ‡°ğŸ‡· ìµœì¢… ë³´ê³ ì„œ (í•œêµ­ì–´ ë²ˆì—­)")
            print("=" * 30)
            
            translation_prompt = PromptTemplate.from_template(
                "Translate the following English text to Korean. Maintain the original structure and formatting, including markdown like headers and bullet points:\n\n{english_text}"
            )
            
            translation_chain = translation_prompt | llm | StrOutputParser()

            korean_report = translation_chain.invoke({"english_text": result['output']})
            
            # <think>...</think> íƒœê·¸ì™€ ê·¸ ë‚´ìš©ì„ ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ ì œê±°
            think_pattern = re.compile(r"<think>.*?</think>\s*", re.DOTALL)
            korean_report = think_pattern.sub("", korean_report).strip()

            print(korean_report)
        else:
            print("\në²ˆì—­í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

        # 6. ìµœì¢… ë³´ê³ ì„œë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        if result['output']:
            report_data = {
                "english_report": result['output'],
                "korean_report": korean_report
            }
            
            base_name = os.path.basename(output)
            identifier = base_name.replace('swot_analysis_', '').replace('.json', '')
            output_path = f'result/deep_research_report_{identifier}.json'

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=4)
            
            print(f"\nâœ… ìµœì¢… ë³´ê³ ì„œê°€ {output_path} ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.") 