from pydantic import BaseModel, Field
from typing import List, Optional, TypedDict
from datetime import date
from langchain_ollama import ChatOllama
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END
import glob
import os
import json
import re

class StartupInvestmentInfo(BaseModel):
    company_name: Optional[str] = Field(None, description="Official company name or corporate name(íšŒì‚¬ëª…)")
    industry: Optional[str] = Field(None, description="Primary business sector or industry vertical (e.g., Manufacturing, IT Services, Biotech, Fintech, Robotics, SaaS)(ì—…ì¢…)")
    funding_stage: Optional[str] = Field(None, description="Current investment stage (e.g., Seed, Series A, Series B, Bridge, Pre-IPO)(íˆ¬ìë‹¨ê³„)")
    last_funding_date: Optional[date] = Field(None, description="Date of the most recent funding round or capital raising(ìµœê·¼ íˆ¬ìì¼)")
    funding_amount_billion: Optional[int] = Field(None, description="Total cumulative funding raised (in 100 million KRW units)(ì´ íˆ¬ìê¸ˆì•¡)")
    valuation_billion: Optional[int] = Field(None, description="Company valuation at the most recent funding round (in 100 million KRW units)(ìµœê·¼ íˆ¬ì í‰ê°€ì•¡)")

    contact_person: Optional[str] = Field(None, description="IR contact person, CEO, or primary point of contact name(ì—°ë½ë‹´ë‹¹ì)")
    contact_phone: Optional[str] = Field(None, description="Company main phone number or contact person's phone(ì—°ë½ì²˜)")

    latest_revenue_million: Optional[int] = Field(None, description="Most recent annual revenue (in million KRW)(ìµœê·¼ ì—°ê°„ ë§¤ì¶œì•¡)")
    operating_profit_million: Optional[int] = Field(None, description="Most recent annual operating profit or EBITDA (in million KRW)(ìµœê·¼ ì—°ê°„ ì˜ì—…ì´ìµ ë˜ëŠ” EBITDA)")
    annual_fixed_cost_million: Optional[int] = Field(None, description="Annual fixed costs or total operating expenses (in million KRW)(ì—°ê°„ ê³ ì •ë¹„ìš© ë˜ëŠ” ì´ ìš´ì˜ë¹„ìš©)")
    cash_runway_months: Optional[int] = Field(None, description="Number of months the company can operate with current cash reserves(í˜„ì¬ í˜„ê¸ˆ ì”ì•¡ìœ¼ë¡œ ìš´ì˜í•  ìˆ˜ ìˆëŠ” ê°œì›” ìˆ˜)")
    breakeven_point: Optional[str] = Field(None, description="Expected timeline or plan to reach break-even point(ì†ìµë¶„ê¸°ì  ë„ë‹¬ ì˜ˆìƒ ì‹œê°„)")

    debt_ratio_percent: Optional[int] = Field(None, description="Debt-to-asset ratio (total debt/total assets Ã— 100)(ë¶€ì±„ë¹„ìœ¨)")
    num_employees: Optional[int] = Field(None, description="Total number of employees or team members(ì „ì²´ ì§ì› ìˆ˜)")

    main_competitors: Optional[List[str]] = Field(None, description="List of primary competitors in the market(ì£¼ìš” ê²½ìŸì‚¬)")
    main_competitor_1: Optional[str] = Field(None, description="Top competitor name or competing product/service(ì£¼ìš” ê²½ìŸì‚¬ 1)")
    main_competitor_2: Optional[str] = Field(None, description="Second major competitor or market share information(ì£¼ìš” ê²½ìŸì‚¬ 2)")

    strengths: Optional[str] = Field(None, description="Core competitive advantages, differentiators, or key strengths (technology, team, patents, customer base)(ì£¼ìš” ê²½ìŸë ¥)")
    weaknesses: Optional[str] = Field(None, description="Internal weaknesses, limitations, or areas needing improvement(ë‚´ë¶€ ì•½ì )")
    opportunities: Optional[str] = Field(None, description="Market opportunities, growth drivers, or external favorable conditions(ì‹œì¥ ê¸°íšŒ)")
    threats: Optional[str] = Field(None, description="Risk factors or threat elements (legal, technical, competitive, market risks)(ìœ„í—˜ìš”ì†Œ)")

    num_patents: Optional[int] = Field(None, description="Number of registered patents owned(ë“±ë¡ëœ íŠ¹í—ˆ ìˆ˜)")
    last_updated: Optional[date] = Field(None, description="Date when this information was last updated or reference date(ìµœì¢… ì—…ë°ì´íŠ¸ ì¼ì)")
    recent_quarter_revenue_million: Optional[int] = Field(None, description="Most recent quarterly revenue (in million KRW)(ìµœê·¼ ë¶„ê¸° ë§¤ì¶œì•¡)")
    annual_growth_percent: Optional[int] = Field(None, description="Year-over-year revenue growth rate (%)")

    main_operating_expenses: Optional[str] = Field(None, description="Breakdown of major operating expense categories (e.g., Personnel 50%, Marketing 20%, R&D 15%)(ì£¼ìš” ìš´ì˜ë¹„ìš© ë¶„í• )")
    founder_background: Optional[str] = Field(None, description="Founder's or CEO's key experience, expertise, or professional background(ì„¤ë¦½ì ë˜ëŠ” CEOì˜ ì£¼ìš” ê²½í—˜, ì „ë¬¸ì„± ë˜ëŠ” ì „ë¬¸ ë°°ê²½)")
    key_personnel: Optional[str] = Field(None, description="Core executives' backgrounds, previous employers, or areas of expertise(ì£¼ìš” ì„ì›ì˜ ë°°ê²½, ì´ì „ ì†Œì† ê¸°ê´€ ë˜ëŠ” ì „ë¬¸ ë¶„ì•¼)")
    board_members: Optional[List[str]] = Field(None, description="Board members, advisors, or mentors list(ì´ì‚¬íšŒ ë©¤ë²„, ì¡°ì–¸ì ë˜ëŠ” ë©˜í†  ëª©ë¡)")

    shareholding_structure: Optional[str] = Field(None, description="Ownership structure and equity distribution (founders, investors, employees)(ì£¼ì£¼ êµ¬ì¡° ë° ì§€ë¶„ ë¶„ë°°)")
    product_roadmap: Optional[str] = Field(None, description="Product/service development roadmap, launch plans, or feature expansion timeline(ì œí’ˆ/ì„œë¹„ìŠ¤ ê°œë°œ ë¡œë“œë§µ, ì¶œì‹œ ê³„íš ë˜ëŠ” ê¸°ëŠ¥ í™•ì¥ ì‹œê°„í‘œ)")
    tech_stack: Optional[List[str]] = Field(None, description="Core technology stack, development tools, infrastructure (e.g., Python, AWS, React)(í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ, ê°œë°œ ë„êµ¬, ì¸í”„ë¼)")

    market_size_billion: Optional[int] = Field(None, description="Target market size or Total Addressable Market (TAM) in 100 million KRW(ëŒ€ìƒ ì‹œì¥ ê·œëª¨ ë˜ëŠ” ì´ ì£¼ì£¼ ê°€ëŠ¥ ì‹œì¥(TAM) 100ë§Œ ì› ë‹¨ìœ„)")
    market_growth_percent: Optional[int] = Field(None, description="Target market's compound annual growth rate (CAGR %)(ëŒ€ìƒ ì‹œì¥ì˜ ë³µí•© ì—°ê°„ ì„±ì¥ë¥ (CAGR %))")
    legal_issues: Optional[bool] = Field(None, description="Whether there are ongoing legal disputes, litigation, or regulatory issues(ë²•ì  ë¶„ìŸ, ì†Œì†¡, ê·œì œ ë¬¸ì œ ì—¬ë¶€)")
    num_ip_rights: Optional[int] = Field(None, description="Total intellectual property rights owned (patents, trademarks, copyrights, designs)(ì´ ì§€ì  ì¬ì‚°ê¶Œ ë³´ìœ  ìˆ˜(íŠ¹í—ˆ, ìƒí‘œ, ì €ì‘ê¶Œ, ë””ìì¸))")

    funding_round: Optional[str] = Field(None, description="Current or recent funding round name (e.g., Series A, Seed Investment)(í˜„ì¬ ë˜ëŠ” ìµœê·¼ íˆ¬ì ë‹¨ê³„ ì´ë¦„(ì˜ˆ: ì‹œë¦¬ì¦ˆ A, ì‹œë“œ íˆ¬ì))")
    main_investors: Optional[List[str]] = Field(None, description="List of major investors (VCs, strategic investors, angel investors)(ì£¼ìš” íˆ¬ìì(VC, ì „ëµ íˆ¬ìì, ì•™ê·¸ë ˆì´ íˆ¬ìì))")
    fund_usage_plan: Optional[str] = Field(None, description="Investment fund allocation plan (e.g., R&D 40%, Marketing 30%, Hiring 20%)(íˆ¬ì ìê¸ˆ ë°°ë¶„ ê³„íš(ì˜ˆ: R&D 40%, ë§ˆì¼€íŒ… 30%, ì±„ìš© 20%))")

    exit_strategy: Optional[str] = Field(None, description="Exit strategy plan (IPO, M&A, acquisition, etc.)(ì¶œêµ¬ ì „ëµ ê³„íš(IPO, M&A, ì¸ìˆ˜ ë“±))")
    rnd_to_revenue_ratio: Optional[int] = Field(None, description="R&D spending as percentage of revenue (%)")
    notes: Optional[str] = Field(None, description="Additional important notes, special circumstances, or other considerations(ì¶”ê°€ ì¤‘ìš” ë©”ëª¨, íŠ¹ë³„ ìƒí™©, ê¸°íƒ€ ê³ ë ¤ì‚¬í•­)")

# State ì •ì˜
class ExtractionState(TypedDict):
    info: StartupInvestmentInfo
    md_content: str
    iteration: int
    no_progress_count: int
    analysis_feedback: str
    total_fields: int
    last_action: str  # "extract", "analyze", "verify"
    verification_index: int  # í˜„ì¬ ê²€ì¦ ì¤‘ì¸ í•„ë“œ ì¸ë±ìŠ¤
    verified_fields: List[str]  # ê²€ì¦ ì™„ë£Œëœ í•„ë“œ ëª©ë¡

# 2. LLM ì¤€ë¹„
llm = ChatOllama(
    model="qwen3:32b",
    base_url="http://192.168.120.102:11434",
    temperature=0
)

parser = JsonOutputParser(pydantic_object=StartupInvestmentInfo)

# í•„ë“œ ì¶”ì¶œ í•¨ìˆ˜ (ì›ë˜ ë°©ì‹ìœ¼ë¡œ ë³µì›)
def extract_fields(state: ExtractionState) -> ExtractionState:
    """MD íŒŒì¼ì—ì„œ ë¹ˆ í•„ë“œë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    info = state["info"]
    md_content = state["md_content"]
    analysis_feedback = state["analysis_feedback"]
    iteration = state["iteration"] + 1
    
    # ë¹ˆ í•„ë“œë“¤ ì°¾ê¸°
    fields_to_fill = [field for field in StartupInvestmentInfo.model_fields if getattr(info, field) is None]
    field_descriptions = [StartupInvestmentInfo.model_fields[field].description for field in fields_to_fill]
    
    # ì§„í–‰ ìƒí™© ì¶œë ¥
    filled_count = state["total_fields"] - len(fields_to_fill)
    fill_ratio = filled_count / state["total_fields"] * 100
    print(f"\n[Iteration {iteration}] Filled: {filled_count}/{state['total_fields']} ({fill_ratio:.1f}%) | Remaining: {len(fields_to_fill)}")
    print(f"  Remaining fields: {fields_to_fill[:10]}{'...' if len(fields_to_fill) > 10 else ''}")
    
    if not fields_to_fill:
        return state
    
    # ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ (ì‹¤ì œ LLM í˜¸ì¶œìš©)
    feedback_prompt = f"\nPrevious analysis feedback: {analysis_feedback}\n" if analysis_feedback else ""
    prompt = f"""
You are an expert data extractor for Korean startup IR documents. Extract specific values from the MD file for the given fields.

CRITICAL RULES:
1. ONLY extract information that is explicitly stated in the document
2. DO NOT generate, guess, or hallucinate any information
3. If information is not clearly present, return null
4. Return ONLY the specified field names as JSON keys
5. Use exact Korean text as found in the document
6. Be sure to write only what is in the MD document content. If you don't know, write None.

DOCUMENT STRUCTURE PATTERNS TO LOOK FOR:

For company_name:
- Look in document titles, headers, or company info sections
- Common Korean labels: "íšŒì‚¬ëª…", "ìƒí˜¸", "ê¸°ì—…ëª…", "íšŒì‚¬ê°œìš”", "Company Info"
- Often appears in tables with company details

For contact_person:
- Look in "Investor Relations" sections, team descriptions, or contact info
- Common patterns: "ëŒ€í‘œ", "CEO", "ì—°ë½ë‹´ë‹¹ì", "Contact"
- Usually appears with names and titles

For contact_phone:
- Look for Korean phone number patterns: +82-xx-xxxx-xxxx or similar
- Common labels: "ì „í™”", "ì—°ë½ì²˜", "Company", "Personal"
- Often in contact or company info sections

For industry:
- Look in business descriptions, company overview sections
- Common labels: "ì—…ì¢…", "ì‚¬ì—…ë¶„ì•¼", "ì—…ì¢…", "ì£¼ìš”ì‚¬ì—…"
- May appear in tables or descriptive text

For funding info (funding_stage, funding_amount_billion, valuation_billion):
- Look for "íˆ¬ì", "ìê¸ˆì¡°ë‹¬", "ì‹œë¦¬ì¦ˆA/B", "ë°¸ë¥˜ì—ì´ì…˜", "Post Value"
- Convert Korean numbers: ì–µ=100million, ì²œë§Œ=10million, ë§Œ=10thousand

For financial data (revenue, profit, costs):
- Look for "ë§¤ì¶œ", "ì˜ì—…ì´ìµ", "ìë³¸ê¸ˆ", "ìš´ì˜ë¹„"
- Convert Korean numbers accordingly

For personnel info (num_employees, team info):
- Look for "ì„ì§ì›ìˆ˜", "ì§ì›ìˆ˜", "êµ¬ì„±ì›", team member lists

For competitors:
- Look for "ê²½ìŸì‚¬", "ê²½ìŸì—…ì²´", competitor analysis sections

For last_updated:
- Look for document dates, publication dates, or "ìµœì¢…ìˆ˜ì •ì¼"
- Date formats may vary (YYYY-MM-DD, YYYYë…„ MMì›” ë“±)

MD document content:
```
{md_content}
{feedback_prompt}
```

Fields to extract: ```{dict(zip(fields_to_fill, field_descriptions))}```

Be sure to write only what is in the MD document content. If you don't know, write None.
Return ONLY a valid JSON object with the specified field names. Extract real values from the document, not placeholder data.
/no_think
"""
    
    # í”„ë¡¬í”„íŠ¸ ì €ì¥ìš© (MD ë‚´ìš© ìƒëµ)
    os.makedirs("prompt", exist_ok=True)
    prompt_for_save = (
        f"You are an expert data extractor for Korean startup IR documents.\n\n"
        f"CRITICAL RULES:\n"
        f"1. ONLY extract information that is explicitly stated in the document\n"
        f"2. DO NOT generate, guess, or hallucinate any information\n"
        f"3. If information is not clearly present, return null\n"
        f"4. Return ONLY the specified field names as JSON keys\n"
        f"5. Use exact Korean text as found in the document\n\n"
        f"DOCUMENT STRUCTURE PATTERNS TO LOOK FOR:\n\n"
        f"For company_name: Look in document titles, headers, company info sections\n"
        f"For contact_person: Look in IR sections, team descriptions, contact info\n"
        f"For contact_phone: Look for Korean phone patterns (+82-xx-xxxx-xxxx)\n"
        f"For industry: Look in business descriptions, company overview sections\n"
        f"For funding info: Look for investment, funding rounds, valuations\n"
        f"For financial data: Look for revenue, profits, costs\n"
        f"For personnel info: Look for employee counts, team info\n"
        f"For competitors: Look for competitive analysis sections\n"
        f"For last_updated: Look for document dates, publication dates\n\n"
        f"NUMBER CONVERSION: ì–µ=100million, ì²œë§Œ=10million, ë§Œ=10thousand\n\n"
        f"MD content: [MD_CONTENT_OMITTED - {len(md_content)} characters]\n\n"
        f"{feedback_prompt}"
        f"Fields to extract: {dict(zip(fields_to_fill, field_descriptions))}\n\n"
        f"Return ONLY a valid JSON object with the specified field names."
    )
    
    with open(f"prompt/iteration_{iteration:02d}_extract_prompt.txt", "w", encoding="utf-8") as f:
        f.write(prompt_for_save)
    print(f"  Prompt saved to: prompt/iteration_{iteration:02d}_extract_prompt.txt")
    
    print(f"  Requesting extraction of {len(fields_to_fill)} fields...")
    result = llm.invoke(prompt)
    
    # LLM ì‘ë‹µ ì €ì¥
    with open(f"prompt/iteration_{iteration:02d}_extract_response.txt", "w", encoding="utf-8") as f:
        f.write(str(result.content))
    print(f"  Response saved to: prompt/iteration_{iteration:02d}_extract_response.txt")
    
    # ê²°ê³¼ ì²˜ë¦¬
    try:
        if isinstance(result.content, str):
            cleaned_content = re.sub(r'<think>.*?</think>', '', result.content, flags=re.DOTALL).strip()
            json_match = re.search(r'\{.*\}', cleaned_content, flags=re.DOTALL)
            if json_match:
                json_str = json_match.group()
                extracted_data = json.loads(json_str)
            else:
                print(f"Warning: No JSON found in response: {cleaned_content[:100]}...")
                extracted_data = {}
        else:
            extracted_data = result.content
    except json.JSONDecodeError as e:
        print(f"Warning: Failed to parse JSON response: {result.content[:100]}...")
        print(f"JSON Error: {e}")
        extracted_data = {}
    
    # ë¬´íš¨í•œ ê°’ë“¤ í•„í„°ë§ (Not specified, ë°ì´í„° ì—†ìŒ ë“±ì€ nullë¡œ ì²˜ë¦¬)
    invalid_values = {
        "Not specified", "not specified", "NOT SPECIFIED",
        "ë°ì´í„° ì—†ìŒ", "ì •ë³´ ì—†ìŒ", "í•´ë‹¹ ì—†ìŒ", "ëª…ì‹œë˜ì§€ ì•ŠìŒ",
        "N/A", "n/a", "NA", "na", "null", "NULL", "None", "NONE",
        "ì •ë³´ ë¶€ì¡±", "í™•ì¸ ë¶ˆê°€", "ë¶ˆëª…", "ë¯¸í™•ì¸", "ë¯¸ëª…ì‹œ",
        "-", "â€”", "â€“", "", "ì •ë³´ê°€ ì—†ìŒ", "ìë£Œ ì—†ìŒ"
    }
    
    # ì¶”ì¶œëœ ë°ì´í„° ê²€ì¦ ë° í•„í„°ë§
    newly_filled = 0
    for k, v in extracted_data.items():
        if k in StartupInvestmentInfo.model_fields and getattr(info, k) is None:
            # ë¬´íš¨í•œ ê°’ì¸ì§€ í™•ì¸
            is_invalid = False
            if isinstance(v, str):
                is_invalid = v.strip() in invalid_values or len(v.strip()) == 0
                # í™˜ê° ë°ì´í„° íŒ¨í„´ ê²€ì‚¬
                if not is_invalid and v.strip():
                    # ì¼ë°˜ì ì¸ í™˜ê° íŒ¨í„´ë“¤
                    hallucination_patterns = [
                        "blue bottle", "john doe", "jane doe", "cafÃ© 24", "starbucks",
                        "sample", "example", "test", "demo", "placeholder"
                    ]
                    v_lower = v.lower()
                    if any(pattern in v_lower for pattern in hallucination_patterns):
                        is_invalid = True
                        print(f"    âš  {k}: '{v}' (í™˜ê° íŒ¨í„´ ê°ì§€ë¨)")
            elif v is None:
                is_invalid = True
            
            if not is_invalid:
                setattr(info, k, v)
                newly_filled += 1
                print(f"    âœ“ {k}: {v}")
            else:
                print(f"    âœ— {k}: '{v}' (ë¬´íš¨í•œ ê°’ìœ¼ë¡œ í•„í„°ë§ë¨)")
    
    print(f"  Successfully filled {newly_filled} new fields")
    
    # ì§„ì „ ì—¬ë¶€ í™•ì¸
    new_remaining_count = len([field for field in StartupInvestmentInfo.model_fields if getattr(info, field) is None])
    previous_remaining_count = len(fields_to_fill)
    
    if new_remaining_count == previous_remaining_count:
        no_progress_count = state["no_progress_count"] + 1
    else:
        no_progress_count = 0
    
    return {
        **state,
        "info": info,
        "iteration": iteration,
        "no_progress_count": no_progress_count,
        "last_action": "extract"
    }

# ë¶„ì„ í•¨ìˆ˜
def analyze_failure(state: ExtractionState) -> ExtractionState:
    """ì¶”ì¶œ ì‹¤íŒ¨ ì´ìœ ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    info = state["info"]
    md_content = state["md_content"]
    iteration = state["iteration"]
    
    # ë¹ˆ í•„ë“œë“¤ ì°¾ê¸° (ì²˜ìŒ 10ê°œë§Œ)
    failed_fields = [field for field in StartupInvestmentInfo.model_fields if getattr(info, field) is None]
    failed_fields_sample = failed_fields[:10]  # 32B ëª¨ë¸ì„ ìœ„í•´ ì²˜ìŒ 10ê°œë§Œ
    
    print("No progress detected. Running failure analysis...")
    
    # ê°„ê²°í•œ ë¶„ì„ í”„ë¡¬í”„íŠ¸
    prompt = (
"""IR Document:```{{md_content}}```

Target Fields for Summarization: ```{{target_fields_list}}```
(ì˜ˆ: "ì—°ê°„ ë§¤ì¶œ", "ìœ ì € ìˆ˜", "íˆ¬ì ìœ ì¹˜ ê¸ˆì•¡", "ê²½ìŸì‚¬", "ê³ ê° í™•ë³´ ì „ëµ")

Instructions:
Based on the IR Document provided, you will generate a summary focused on the 'Target Fields for Summarization'. This summary will be created in a "Chain of Density" manner, progressively becoming more detailed and entity-rich across 3 stages, while trying to maintain a reasonable overall length.

For each stage, focus on incorporating information related to the 'Target Fields for Summarization'.

---

**Stage 1: Sparse Summary (Key Facts Extraction)**
*   **Objective:** Identify and extract the most direct values or key statements for each of the 'Target Fields for Summarization' from the IR document. If a direct value is not found, state "ì •ë³´ ì—†ìŒ" or a brief reason.
*   **Output:** A very concise summary (1-2 sentences per field, or a bulleted list) presenting these extracted key facts with minimal context. Focus on accuracy and directness.
    *   Example for "ì—°ê°„ ë§¤ì¶œ": "2023ë…„ ì—°ê°„ ë§¤ì¶œ: 10ì–µ ì›." or "ì—°ê°„ ë§¤ì¶œ: í˜„ì¬ ë¹„ê³µê°œ, ì„±ì¥ì„¸ ê°•ì¡°."
    *   Example for "ê²½ìŸì‚¬": "ì£¼ìš” ê²½ìŸì‚¬: Aì‚¬, Bì‚¬ ì–¸ê¸‰." or "ê²½ìŸì‚¬: êµ¬ì²´ì  ì–¸ê¸‰ ì—†ìŒ, ì‹œì¥ ì„ ë„ ëª©í‘œ."

---

**Stage 2: Denser Summary (Contextual Integration)**
*   **Objective:** Re-write the Stage 1 summary to be more fluent and integrated. Add relevant context, brief explanations, or supporting details for the extracted field values from the surrounding text in the IR document. If multiple target fields are related, start to show these connections.
*   **Guidelines:**
    *   Do not simply list facts; weave them into a coherent narrative.
    *   Incorporate 1-2 additional pieces of relevant information (entities, brief explanations, or supporting data points from the IR document) for each target field, or for the summary as a whole, compared to Stage 1.
    *   Maintain conciseness but improve readability and information flow.
    *   If a field had "ì •ë³´ ì—†ìŒ" in Stage 1, explain briefly why based on the document (e.g., "ì´ˆê¸° ë‹¨ê³„ë¡œ ë§¤ì¶œ ë¹„ê³µê°œ ìƒíƒœì´ë©°, ëŒ€ì‹  ì‚¬ìš©ì ì¦ê°€ìœ¨ì— ì§‘ì¤‘í•˜ê³  ìˆìŒ.").
*   **Output:** A more detailed paragraph-style summary that connects the key facts with their immediate context.

---

**Stage 3: Densest Summary (Comprehensive Overview & Insights)**
*   **Objective:** Create the most informative summary by further enriching the Stage 2 summary. Incorporate more nuanced details, interconnections between different target fields, and potentially implied insights or strategic importance as suggested by the IR document.
*   **Guidelines:**
    *   Fuse and compress information effectively to add more detail without excessive length.
    *   Incorporate another 1-2 significant pieces of information (e.g., specific strategies related to a field, quantitative backing, future outlook related to a field, comparisons if available) for each target field or for the overall narrative.
    *   The summary should provide a good, self-contained overview of the startup's position regarding the target fields.
    *   If information for a field remains absent, reflect this accurately within the broader context.
*   **Output:** A rich, concise, and insightful summary that provides a comprehensive understanding of the IR document's content related to the specified target fields.

---

Please generate the 3-stage CoD summary focusing on the 'Target Fields for Summarization'.
Present each stage clearly labeled./no_think"""
    )
    
    # ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì €ì¥ìš© (MD ë‚´ìš© ìƒëµ)
    os.makedirs("prompt", exist_ok=True)
    prompt_for_save = (
        "Analyze why these fields couldn't be extracted from the Korean startup IR document:\n\n"
        f"Failed fields: {failed_fields_sample}\n\n"
        "For each field, provide:\n"
        "- Korean keywords to look for\n"
        "- Likely section/table names\n"
        "- Alternative extraction approach\n\n"
        f"MD content: [MD_CONTENT_OMITTED - {len(md_content)} characters]\n\n"
        "Keep response concise. Focus on actionable extraction tips."
    )
    
    with open(f"prompt/iteration_{iteration:02d}_analyze_prompt.txt", "w", encoding="utf-8") as f:
        f.write(prompt_for_save)
    print(f"  Analysis prompt saved to: prompt/iteration_{iteration:02d}_analyze_prompt.txt")
    
    result = llm.invoke(prompt)
    analysis_feedback = re.sub(r'<think>.*?</think>', '', result.content, flags=re.DOTALL).strip()
    
    # ë¶„ì„ ì‘ë‹µ ì €ì¥
    with open(f"prompt/iteration_{iteration:02d}_analyze_response.txt", "w", encoding="utf-8") as f:
        f.write(analysis_feedback)
    print(f"  Analysis response saved to: prompt/iteration_{iteration:02d}_analyze_response.txt")
    
    print(f"  Analysis feedback received: {len(analysis_feedback)} characters")
    
    return {
        **state,
        "analysis_feedback": analysis_feedback,
        "no_progress_count": state["no_progress_count"],  # ë¶„ì„ í›„ì—ë„ ì¹´ìš´íŠ¸ ìœ ì§€
        "last_action": "analyze"
    }

# ì¢…ë£Œ ì¡°ê±´ ì²´í¬
def should_continue(state: ExtractionState) -> str:
    """ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    info = state["info"]
    last_action = state.get("last_action", "start")
    
    # ê²€ì¦ ì™„ë£Œ í™•ì¸
    if last_action == "verify_complete":
        return "end"
    
    # ê²€ì¦ ì¤‘ì¸ ê²½ìš° ê³„ì† ê²€ì¦
    if last_action == "verify":
        return "verify"
    
    # ì¶”ì¶œì´ ëë‚¬ëŠ”ì§€ í™•ì¸
    fields_to_fill = [field for field in StartupInvestmentInfo.model_fields if getattr(info, field) is None]
    
    # ëª¨ë“  í•„ë“œê°€ ì±„ì›Œì¡Œìœ¼ë©´ ê²€ì¦ ì‹œì‘
    if not fields_to_fill:
        filled_count = len([field for field in StartupInvestmentInfo.model_fields if getattr(info, field) is not None])
        print(f"ì¶”ì¶œ ì™„ë£Œ! ì±„ì›Œì§„ í•„ë“œ: {filled_count}ê°œ")
        print("ğŸ” ê²€ì¦ ë‹¨ê³„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        return "verify"
    
    # ì§„ì „ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if state["no_progress_count"] >= 5:
        filled_count = len([field for field in StartupInvestmentInfo.model_fields if getattr(info, field) is not None])
        print(f"ì¶”ì¶œ ì™„ë£Œ (ì§„ì „ ì—†ìŒ). ì±„ì›Œì§„ í•„ë“œ: {filled_count}ê°œ")
        
        # ì±„ì›Œì§„ í•„ë“œê°€ ìˆìœ¼ë©´ ê²€ì¦ ì‹œì‘
        if filled_count > 0:
            print("ğŸ” ê²€ì¦ ë‹¨ê³„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            return "verify"
        else:
            print("ê²€ì¦í•  í•„ë“œê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return "end"
    
    # ë°©ê¸ˆ analyzeë¥¼ í–ˆë‹¤ë©´ ë°˜ë“œì‹œ extractë¡œ
    if last_action == "analyze":
        return "extract"
    
    # 2íšŒ ì´ìƒ ì§„ì „ì´ ì—†ìœ¼ë©´ ë¶„ì„ ì‹¤í–‰
    if state["no_progress_count"] >= 2:
        return "analyze"
    
    # ê·¸ ì™¸ì—ëŠ” ê³„ì† ì¶”ì¶œ
    return "extract"

# ê·¸ë˜í”„ ìƒì„±
workflow = StateGraph(ExtractionState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("extract", extract_fields)
workflow.add_node("analyze", analyze_failure)
workflow.add_node("verify", verify_field)

# ì‹œì‘ì  ì„¤ì •
workflow.set_entry_point("extract")

# ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€
workflow.add_conditional_edges(
    "extract",
    should_continue,
    {
        "extract": "extract",
        "analyze": "analyze",
        "verify": "verify",
        "end": END
    }
)

workflow.add_conditional_edges(
    "analyze",
    should_continue,
    {
        "extract": "extract",
        "analyze": "analyze",
        "verify": "verify",
        "end": END
    }
)

workflow.add_conditional_edges(
    "verify",
    should_continue,
    {
        "verify": "verify",
        "end": END
    }
)

# ê·¸ë˜í”„ ì»´íŒŒì¼
app = workflow.compile()

# 3. md íŒŒì¼ ì½ê¸° ë° ì •ë³´ ì¶”ì¶œ
with open("./data/ë¸”ë£¨ë¸Œë¦¿ì§€ê¸€ë¡œë²Œ.md", "r", encoding="utf-8") as f:
    md_file_content = f.read()

print("=== Starting extraction from ë¸”ë£¨ë¸Œë¦¿ì§€ê¸€ë¡œë²Œ.md ===")
print(f"MD file content length: {len(md_file_content)} characters")

# ì´ˆê¸° ìƒíƒœ ì„¤ì •
initial_state = ExtractionState(
    info=StartupInvestmentInfo(),
    md_content=md_file_content,
    iteration=0,
    no_progress_count=0,
    analysis_feedback="",
    total_fields=len(StartupInvestmentInfo.model_fields),
    last_action="start",
    verification_index=0,
    verified_fields=[]
)

# ê·¸ë˜í”„ ì‹¤í–‰
final_state = app.invoke(initial_state)
info = final_state["info"]

print(f"\n=== Final Results ===")
final_filled = len([field for field in StartupInvestmentInfo.model_fields if getattr(info, field) is not None])
final_ratio = final_filled / len(StartupInvestmentInfo.model_fields) * 100
print(f"Total filled: {final_filled}/{len(StartupInvestmentInfo.model_fields)} ({final_ratio:.1f}%)")
print(f"Verified fields: {len(final_state['verified_fields'])}")
print(f"Final result:")

# ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
os.makedirs("result", exist_ok=True)

try:
    # JSON í˜•íƒœë¡œ ì €ì¥ ì‹œë„
    info_dict = info.model_dump()
    
    # ë‚ ì§œ í•„ë“œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
    for key, value in info_dict.items():
        if hasattr(value, 'isoformat'):  # date ê°ì²´ì¸ ê²½ìš°
            info_dict[key] = value.isoformat()
    
    json_result = json.dumps(info_dict, ensure_ascii=False, indent=2)
    
    with open("result/extraction_result.json", "w", encoding="utf-8") as f:
        f.write(json_result)
    print(f"âœ… Results saved to: result/extraction_result.json")
    
    # JSON í˜•íƒœë¡œ ì¶œë ¥ë„ ì‹œë„
    print("=== JSON í˜•íƒœ ê²°ê³¼ ===")
    print(json_result)
    
except Exception as e:
    print(f"âŒ JSON ì €ì¥ ì‹¤íŒ¨: {e}")
    print("ğŸ“ TXT í˜•íƒœë¡œ ì €ì¥ ì‹œë„...")
    
    try:
        # TXT í˜•íƒœë¡œ ì €ì¥
        info_dict = info.model_dump()
        
        result_text = f"=== ë¡œë³´ìŠ¤ IR ì¶”ì¶œ ê²°ê³¼ ===\n"
        result_text += f"ì¶”ì¶œ ì™„ë£Œ: {final_filled}/{len(StartupInvestmentInfo.model_fields)} ({final_ratio:.1f}%)\n"
        result_text += f"ê²€ì¦ ì™„ë£Œ: {len(final_state['verified_fields'])}ê°œ í•„ë“œ\n\n"
        
        result_text += "=== ì±„ì›Œì§„ í•„ë“œ ===\n"
        filled_fields = {k: v for k, v in info_dict.items() if v is not None}
        for field_name, value in filled_fields.items():
            field_desc = StartupInvestmentInfo.model_fields[field_name].description
            result_text += f"âœ“ {field_name}: {value}\n"
        
        result_text += "\n=== ë¹ˆ í•„ë“œ ===\n"
        empty_fields = {k: v for k, v in info_dict.items() if v is None}
        for field_name, value in empty_fields.items():
            field_desc = StartupInvestmentInfo.model_fields[field_name].description
            result_text += f"âœ— {field_name} ({field_desc}): ë°ì´í„° ì—†ìŒ\n"
        
        with open("result/extraction_result.txt", "w", encoding="utf-8") as f:
            f.write(result_text)
        print(f"âœ… Results saved to: result/extraction_result.txt")
        
    except Exception as txt_error:
        print(f"âŒ TXT ì €ì¥ë„ ì‹¤íŒ¨: {txt_error}")

# í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ì¶œë ¥
print("\n=== í…ìŠ¤íŠ¸ í˜•íƒœ ê²°ê³¼ ===")
info_dict = info.model_dump()
for field_name, value in info_dict.items():
    field_desc = StartupInvestmentInfo.model_fields[field_name].description
    print(f"{field_name} ({field_desc}): {value}")

# ë¹ˆ í•„ë“œì™€ ì±„ì›Œì§„ í•„ë“œ êµ¬ë¶„í•´ì„œ ì¶œë ¥
print(f"\n=== ì±„ì›Œì§„ í•„ë“œ ===")
filled_fields = {k: v for k, v in info_dict.items() if v is not None}
for field_name, value in filled_fields.items():
    field_desc = StartupInvestmentInfo.model_fields[field_name].description
    print(f"âœ“ {field_name}: {value}")

print(f"\n=== ë¹ˆ í•„ë“œ ===")
empty_fields = {k: v for k, v in info_dict.items() if v is None}
for field_name, value in empty_fields.items():
    field_desc = StartupInvestmentInfo.model_fields[field_name].description
    print(f"âœ— {field_name} ({field_desc}): ë°ì´í„° ì—†ìŒ")

# í•„ë“œ ê²€ì¦ í•¨ìˆ˜
def verify_field(state: ExtractionState) -> ExtractionState:
    """ì±„ì›Œì§„ í•„ë“œê°’ì„ MD íŒŒì¼ê³¼ ëŒ€ì¡°í•˜ì—¬ ê²€ì¦í•©ë‹ˆë‹¤."""
    info = state["info"]
    md_content = state["md_content"]
    verification_index = state["verification_index"]
    verified_fields = state["verified_fields"].copy()
    
    # ì±„ì›Œì§„ í•„ë“œë“¤ë§Œ ê°€ì ¸ì˜¤ê¸°
    filled_fields = [(field, getattr(info, field)) for field in StartupInvestmentInfo.model_fields 
                    if getattr(info, field) is not None]
    
    if verification_index >= len(filled_fields):
        print("ëª¨ë“  í•„ë“œ ê²€ì¦ ì™„ë£Œ!")
        return {
            **state,
            "last_action": "verify_complete"
        }
    
    current_field, current_value = filled_fields[verification_index]
    field_description = StartupInvestmentInfo.model_fields[current_field].description
    
    print(f"\n[Verification {verification_index + 1}/{len(filled_fields)}] ê²€ì¦ ì¤‘: {current_field}")
    print(f"  í˜„ì¬ ê°’: {current_value}")
    print(f"  ì„¤ëª…: {field_description}")
    
    # ê²€ì¦ í”„ë¡¬í”„íŠ¸
    prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ ìŠ¤íƒ€íŠ¸ì—… IR ë¬¸ì„œì˜ ë°ì´í„° ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì¶”ì¶œëœ í•„ë“œê°’ì´ MD ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦í•˜ê³  ê·¼ê±°ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.

ê²€ì¦ ëŒ€ìƒ:
- í•„ë“œëª…: {current_field}
- í•„ë“œ ì„¤ëª…: {field_description}  
- ì¶”ì¶œëœ ê°’: {current_value}

MD ë¬¸ì„œ ë‚´ìš©:
```
{md_content}
```

ê²€ì¦ ì ˆì°¨:
1. MD ë¬¸ì„œì—ì„œ í•´ë‹¹ í•„ë“œì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”
2. ì¶”ì¶œëœ ê°’ì´ ë¬¸ì„œ ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”
3. ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œì˜ êµ¬ì²´ì ì¸ ë¬¸ì¥ì´ë‚˜ í‘œí˜„ì„ ì¸ìš©í•´ì£¼ì„¸ìš”

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "field_name": "{current_field}",
    "extracted_value": "{current_value}",
    "is_valid": true/false,
    "evidence": "ë¬¸ì„œì—ì„œ ì°¾ì€ êµ¬ì²´ì ì¸ ê·¼ê±° ë¬¸ì¥",
    "corrected_value": "ìˆ˜ì •ì´ í•„ìš”í•œ ê²½ìš° ì˜¬ë°”ë¥¸ ê°’ (is_validê°€ trueë©´ null)",
    "reasoning": "ê²€ì¦ ê·¼ê±° ë° íŒë‹¨ ì´ìœ "
}}

ì¤‘ìš”í•œ ê·œì¹™:
- ë¬¸ì„œì— ëª…ì‹œì ìœ¼ë¡œ ë‚˜ì™€ìˆëŠ” ì •ë³´ë§Œ ìœ íš¨í•˜ë‹¤ê³  íŒë‹¨
- ì¶”ë¡ ì´ë‚˜ ì¶”ì¸¡ì€ ìœ íš¨í•˜ì§€ ì•ŠìŒ
- ìˆ«ìì˜ ê²½ìš° ë‹¨ìœ„ì™€ ì •í™•í•œ ê°’ í™•ì¸
- ë‚ ì§œì˜ ê²½ìš° ì •í™•í•œ í˜•ì‹ í™•ì¸
- ê·¼ê±°ê°€ ë¶ˆë¶„ëª…í•˜ë©´ is_validë¥¼ falseë¡œ ì„¤ì •

JSONë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
"""
    
    # í”„ë¡¬í”„íŠ¸ ì €ì¥
    os.makedirs("prompt/verification", exist_ok=True)
    prompt_for_save = (
        f"í•„ë“œ ê²€ì¦ í”„ë¡¬í”„íŠ¸\n\n"
        f"ê²€ì¦ ëŒ€ìƒ:\n"
        f"- í•„ë“œëª…: {current_field}\n"
        f"- í•„ë“œ ì„¤ëª…: {field_description}\n"
        f"- ì¶”ì¶œëœ ê°’: {current_value}\n\n"
        f"MD ë‚´ìš©: [MD_CONTENT_OMITTED - {len(md_content)} ë¬¸ì]\n\n"
        f"ê²€ì¦ ì ˆì°¨: MD ë¬¸ì„œì—ì„œ ê·¼ê±° ì°¾ê¸°, ê°’ ì¼ì¹˜ ì—¬ë¶€ íŒë‹¨, êµ¬ì²´ì  ì¸ìš©\n"
        f"ì‘ë‹µ: JSON í˜•ì‹ìœ¼ë¡œ is_valid, evidence, corrected_value, reasoning í¬í•¨"
    )
    
    with open(f"prompt/verification/verify_{current_field}.txt", "w", encoding="utf-8") as f:
        f.write(prompt_for_save)
    print(f"  ê²€ì¦ í”„ë¡¬í”„íŠ¸ ì €ì¥: prompt/verification/verify_{current_field}.txt")
    
    result = llm.invoke(prompt)
    
    # ì‘ë‹µ ì €ì¥
    with open(f"prompt/verification/verify_{current_field}_response.txt", "w", encoding="utf-8") as f:
        f.write(str(result.content))
    print(f"  ê²€ì¦ ì‘ë‹µ ì €ì¥: prompt/verification/verify_{current_field}_response.txt")
    
    # ê²°ê³¼ ì²˜ë¦¬
    try:
        if isinstance(result.content, str):
            cleaned_content = re.sub(r'<think>.*?</think>', '', result.content, flags=re.DOTALL).strip()
            json_match = re.search(r'\{.*\}', cleaned_content, flags=re.DOTALL)
            if json_match:
                json_str = json_match.group()
                verification_result = json.loads(json_str)
            else:
                print(f"ê²½ê³ : ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {cleaned_content[:100]}...")
                verification_result = {"is_valid": True}  # ê¸°ë³¸ê°’ìœ¼ë¡œ ìœ íš¨í•˜ë‹¤ê³  íŒë‹¨
        else:
            verification_result = result.content
    except json.JSONDecodeError as e:
        print(f"ê²½ê³ : JSON íŒŒì‹± ì‹¤íŒ¨: {result.content[:100]}...")
        print(f"JSON ì˜¤ë¥˜: {e}")
        verification_result = {"is_valid": True}  # ê¸°ë³¸ê°’ìœ¼ë¡œ ìœ íš¨í•˜ë‹¤ê³  íŒë‹¨
    
    # ê²€ì¦ ê²°ê³¼ ì²˜ë¦¬
    is_valid = verification_result.get("is_valid", True)
    evidence = verification_result.get("evidence", "ê·¼ê±° ì—†ìŒ")
    corrected_value = verification_result.get("corrected_value")
    reasoning = verification_result.get("reasoning", "ê²€ì¦ ì™„ë£Œ")
    
    if is_valid:
        print(f"  âœ… ê²€ì¦ í†µê³¼")
        print(f"  ğŸ“ ê·¼ê±°: {evidence[:100]}...")
    else:
        print(f"  âŒ ê²€ì¦ ì‹¤íŒ¨")
        print(f"  ğŸ“ ì´ìœ : {reasoning}")
        print(f"  ğŸ”§ ìˆ˜ì •ê°’: {corrected_value}")
        
        # ê°’ ìˆ˜ì •
        if corrected_value is not None:
            setattr(info, current_field, corrected_value)
            print(f"  ğŸ”„ {current_field} ê°’ì„ '{corrected_value}'ë¡œ ìˆ˜ì •")
        else:
            setattr(info, current_field, None)
            print(f"  ğŸ—‘ï¸ {current_field} ê°’ì„ nullë¡œ ë³€ê²½")
    
    # ê²€ì¦ ì™„ë£Œëœ í•„ë“œì— ì¶”ê°€
    verified_fields.append(current_field)
    
    return {
        **state,
        "info": info,
        "verification_index": verification_index + 1,
        "verified_fields": verified_fields,
        "last_action": "verify"
    }